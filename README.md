# Stats507_final
# Analyzing Emotions in Images with ViT and CLIP Models

## Overview
This project uses advanced transformer-based architectures, Vision Transformer (ViT) and CLIP, to classify emotions in images. The EmoSet dataset is leveraged to fine-tune these models for multi-class emotion classification. The project includes features like saliency maps for interpretability and robust evaluation metrics.

---


